[
  {
    "objectID": "dailyex21.html",
    "href": "dailyex21.html",
    "title": "ESS 330 - Daily Exercise 21",
    "section": "",
    "text": "Daily Assignment 21\n\nLibrary Code\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(tsibble)\n\nRegistered S3 method overwritten by 'tsibble':\n  method               from \n  as_tibble.grouped_df dplyr\n\nAttaching package: 'tsibble'\n\nThe following object is masked from 'package:lubridate':\n\n    interval\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, union\n\nlibrary(feasts)\n\nLoading required package: fabletools\n\nAttaching package: 'fabletools'\n\nThe following object is masked from 'package:yardstick':\n\n    accuracy\n\nThe following object is masked from 'package:parsnip':\n\n    null_model\n\nThe following objects are masked from 'package:infer':\n\n    generate, hypothesize\n\nlibrary(dataRetrieval)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\n\n\nData Import\n\n# Example: Cache la Poudre River at Mouth (USGS site 06752260)\npoudre_flow &lt;- readNWISdv(siteNumber = \"06752260\",    # Download data from USGS for site 06752260\n                          parameterCd = \"00060\",      # Parameter code 00060 = discharge in cfs)\n                          startDate = \"2013-01-01\",   # Set the start date\n                          endDate = \"2023-12-31\") |&gt;  # Set the end date\n  renameNWISColumns() |&gt;                              # Rename columns to standard names (e.g., \"Flow\", \"Date\")\n  mutate(Date = yearmonth(Date)) |&gt;                   # Convert daily Date values into a year-month format (e.g., \"2023 Jan\")\n  group_by(Date) |&gt;                                   # Group the data by the new monthly Date\n  summarise(Flow = mean(Flow))                       # Calculate the average daily flow for each month\n\nGET:https://waterservices.usgs.gov/nwis/dv/?site=06752260&format=waterml%2C1.1&ParameterCd=00060&StatCd=00003&startDT=2013-01-01&endDT=2023-12-31\n\n\n\n\nConverting Data Frame and Extracting Components\n\n# Converting to Tibble Frame\ntibble_poudre &lt;- as_tibble(poudre_flow) |&gt; \n  as_tsibble(index = Date)\n\n# Creating Model\npoudre_decomp &lt;- tibble_poudre |&gt;\n  model(STL(Flow ~ season(window = \"periodic\")))\n\n# Extracting Components\npoudre_components &lt;- components(poudre_decomp)\n\n\n\nPlotting the Time Series Analysis\n\n# Plotting Data Series \npoudre_plot &lt;- poudre_components |&gt; \n  autoplot() +\n  labs(title = \"STL Decomposition of Poudre Flow\",\n       y = \"Flow (cfs)\", x = \"Date\") +\n  theme_minimal()\n\npoudre_plot\n\n\n\n\n\n\n\n# Animating the Plot\npoudre_plotly &lt;- ggplotly(poudre_plot)\n\npoudre_plotly\n\n\n\n\n\n\n\nVisualizing Seasonal Patterns\n\npoudre_subseries &lt;- tibble_poudre |&gt; \n  gg_subseries(Flow) +\n  labs(title = \"Seasonal Subseries Plot of Poudre River Flow\",\n       y = \"Average Flow (cfs)\", x = \"Month\") +\n  theme_minimal()\n\npoudre_subseries\n\n\n\n\n\n\n\n\n\n\nData Analysis\n\nWith each of the time series plots, we can clearly see that there is a spike in the flow of the gauge around May and June. This makes sense as this is when the heaviest amount of rain is typically found in Northern Colorado. There is also the fact that over the years, there is an overall decrease in the amount of flow, meaning that there is less precipitation to help initiate flow. The sub-series allows for the data to be sorted by the months rather than a linear, and shows if there is any outliers that may screw the analysis of the seasons. We can see this specifically in September and slightly in April, but with all of the data sorted by month, we can see the average flow for each month and easily find the season with the highest amount of flow.\n\n\n\n\nDaily Assignment 22\n\nLibrary Code\n\nlibrary(modeltime)\nlibrary(tidymodels)\nlibrary(timetk)\nlibrary(yardstick)\nlibrary(dplyr)\nlibrary(lubridate)\n\n\n\nSplitting Data for Models\n\ntibble_poudre_fixed &lt;- tibble_poudre %&gt;%\n    mutate(Date = lubridate::ym(Date)) %&gt;%\n    arrange(Date) %&gt;%\n    ungroup()\n\ntibble_poudre_fixed &lt;- tibble_poudre_fixed %&gt;% as_tibble()\n\nsplits &lt;- time_series_split(tibble_poudre_fixed, assess = 12, cumulative = TRUE)\n\nUsing date_var: Date\n\ntraining &lt;-  training(splits)\ntesting  &lt;-  testing(splits)\n\n\n\nModels\n\nmodel_prophet &lt;- prophet_reg(\n    seasonality_yearly = TRUE\n) %&gt;%\n    set_engine(\"prophet\")\n\nmodel_arima &lt;- arima_reg() %&gt;%\n    set_engine(\"auto_arima\")\n\nmodel_fit_prophet &lt;- model_prophet %&gt;%\n    fit(Flow ~ Date, data = training)\n\nDisabling weekly seasonality. Run prophet with weekly.seasonality=TRUE to override this.\n\n\nDisabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n\nmodel_fit_arima &lt;- model_arima %&gt;%\n    fit(Flow ~ Date, data = training)\n\nfrequency = 12 observations per 1 year\n\nmodels_table &lt;- modeltime_table(\n    model_fit_prophet,\n    model_fit_arima\n)\n\ncalibration_tbl &lt;- models_table %&gt;%\n    modeltime_calibrate(new_data = testing)\n\nfuture_forecast_tbl &lt;- models_table %&gt;%\n    modeltime_refit(data = tibble_poudre_fixed) %&gt;%   \n    modeltime_forecast(h = \"12 months\", actual_data = tibble_poudre_fixed)\n\nDisabling weekly seasonality. Run prophet with weekly.seasonality=TRUE to override this.\nDisabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n\n\nfrequency = 12 observations per 1 year\n\nfuture_forecast_tbl %&gt;%\n    plot_modeltime_forecast(.interactive = FALSE)\n\nWarning: ✖ Expecting the following names to be in the data frame: .conf_hi, .conf_lo.\nℹ Proceeding with '.conf_interval_show = FALSE' to visualize the forecast without confidence intervals.\nAlternatively, try using `modeltime_calibrate()` before forecasting to add confidence intervals.\n\n\n\n\n\n\n\n\n\n\n\nImporting the Actual Streamflows\n\npoudre_flow_2024 &lt;- readNWISdv(siteNumber = \"06752260\",    # Download data from USGS for site 06752260\n                          parameterCd = \"00060\",      # Parameter code 00060 = discharge in cfs)\n                          startDate = \"2024-01-01\",   # Set the start date\n                          endDate = \"2024-12-31\") |&gt;  # Set the end date\n  renameNWISColumns() |&gt;                              # Rename columns to standard names (e.g., \"Flow\", \"Date\")\n  mutate(Date = yearmonth(Date)) |&gt;                   # Convert daily Date values into a year-month format (e.g., \"2023 Jan\")\n  group_by(Date) |&gt;                                   # Group the data by the new monthly Date\n  summarise(Flow = mean(Flow))                       # Calculate the average daily flow for each month\n\nGET:https://waterservices.usgs.gov/nwis/dv/?site=06752260&format=waterml%2C1.1&ParameterCd=00060&StatCd=00003&startDT=2024-01-01&endDT=2024-12-31\n\ncombined_poudre &lt;- bind_rows(poudre_flow, poudre_flow_2024)\n\ncombined_tibble_poudre &lt;- as_tibble(combined_poudre) |&gt; \n  as_tsibble(index = Date)\n\n\n\nComparing the Models\n\n# Filter only 2024 predictions\npredictions_2024 &lt;- future_forecast_tbl %&gt;%\n    filter(.index &gt;= yearmonth(\"2024 Jan\")) %&gt;%\n    select(.index, .value, .model_desc)\n\nWarning: There was 1 warning in `filter()`.\nℹ In argument: `.index &gt;= yearmonth(\"2024 Jan\")`.\nCaused by warning:\n! Incompatible methods (\"&gt;=.Date\", \"&gt;=.vctrs_vctr\") for \"&gt;=\"\n\nactual_2024 &lt;- poudre_flow_2024 %&gt;%\n    rename(.index = Date,\n           actual_flow = Flow)\n\ncomparison_tbl &lt;- left_join(predictions_2024, actual_2024, by = \".index\")\n\ncomparison_tbl %&gt;%\n    group_by(.model_desc) %&gt;%\n    summarise(\n        RMSE = rmse_vec(truth = actual_flow, estimate = .value),\n        MAE  = mae_vec(truth = actual_flow, estimate = .value),\n        MAPE = mape_vec(truth = actual_flow, estimate = .value)\n    )\n\n# A tibble: 2 × 4\n  .model_desc                      RMSE   MAE  MAPE\n  &lt;chr&gt;                           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 PROPHET                          226.  164.  293.\n2 UPDATE: ARIMA(0,0,2)(0,1,1)[12]  208.  110.  117.\n\n\n\n\nPlotting the Models\n\nlibrary(ggplot2)\n\ncomparison_tbl %&gt;%\n    ggplot(aes(x = .index)) +\n    geom_line(aes(y = actual_flow), color = \"black\", size = 1, linetype = \"dashed\") +\n    geom_line(aes(y = .value, color = .model_desc), size = 1) +\n    labs(title = \"Actual vs Predicted Streamflows (2024)\",\n         y = \"Flow (cfs)\",\n         x = \"Month\",\n         color = \"Model\") +\n    theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nFitting the Linear Model\n\n# For one model at a time (example: Prophet model)\nprophet_comparison &lt;- comparison_tbl %&gt;%\n    filter(.model_desc == \"PROPHET\")\n\n# Fit linear model: actual vs predicted\nlm_prophet &lt;- lm(actual_flow ~ .value, data = prophet_comparison)\n\nsummary(lm_prophet)$r.squared\n\n[1] 0.85037\n\narima_comparison &lt;- comparison_tbl %&gt;%\n    filter(.model_desc == \"UPDATE: ARIMA(0,0,2)(0,1,1)[12]\")\n\nlm_arima &lt;- lm(actual_flow ~ .value, data = arima_comparison)\n\nglance(lm_arima) %&gt;%\n    select(r.squared)\n\n# A tibble: 1 × 1\n  r.squared\n      &lt;dbl&gt;\n1     0.919\n\n\n\n\nPlotting\n\n# Compute R² for both models\nlm_prophet &lt;- lm(actual_flow ~ .value, data = comparison_tbl %&gt;% filter(.model_desc == \"PROPHET\"))\nlm_arima &lt;- lm(actual_flow ~ .value, data = comparison_tbl %&gt;% filter(.model_desc == \"UPDATE: ARIMA(0,0,2)(0,1,1)[12]\"))\n\nr_squared_prophet &lt;- summary(lm_prophet)$r.squared\nr_squared_arima &lt;- summary(lm_arima)$r.squared\n\n# Plot for both models\ncomparison_tbl %&gt;%\n    ggplot(aes(x = .value, y = actual_flow, color = .model_desc)) +\n    geom_point(size = 3) +\n    geom_abline(intercept = 0, slope = 1, color = \"black\", linetype = \"dashed\", size = 1) +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    annotate(\"text\", x = max(comparison_tbl$.value) * 0.7, \n             y = max(comparison_tbl$actual_flow) * 0.9, \n             label = paste(\"R² (Prophet) = \", round(r_squared_prophet, 3)), color = \"blue\", size = 5) +\n    annotate(\"text\", x = max(comparison_tbl$.value) * 0.7, \n             y = max(comparison_tbl$actual_flow) * 0.85, \n             label = paste(\"R² (ARIMA) = \", round(r_squared_arima, 3)), color = \"red\", size = 5) +\n    labs(\n        title = \"Predicted vs Observed Streamflow (All Models)\",\n        x = \"Predicted Flow (cfs)\",\n        y = \"Observed Flow (cfs)\",\n        color = \"Model\"\n    ) +\n    theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nModel Analysis\nWhile both models have high R2s, when compared in a linear model, they look to be far from the observed flows. Arima has a higher R2 which details a more accurate model. The peak of the observations were far off from the observed flow, which matches with the comparison of the models to the observed flow from 2024. However, it was able to predict the periods where the flow would spike. Overall, Arima is the best model for this prediction and created a fairly accurate read."
  }
]